{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19d8b96a",
   "metadata": {},
   "source": [
    "Advanced Analytics\n",
    "Assignment 1\n",
    "Group 11\n",
    "Peter Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b95455a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muddy/.local/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "# https://medium.com/vickdata/a-simple-guide-to-scikit-learn-pipelines-4ac0d974bdcf\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1135a03d",
   "metadata": {},
   "source": [
    "# Column names\n",
    "['client_id', 'homebanking_active', 'has_homebanking', 'has_insurance_21', 'has_insurance_23', 'has_life_insurance_fixed_cap', 'has_life_insurance_decreasing_cap', 'has_fire_car_other_insurance', 'has_personal_loan', 'has_mortgage_loan', 'has_current_account', 'has_pension_saving', 'has_savings_account', 'has_savings_account_starter', 'has_current_account_starter', 'bal_insurance_21', 'bal_insurance_23', 'cap_life_insurance_fixed_cap', 'cap_life_insurance_decreasing_cap', 'prem_fire_car_other_insurance', 'bal_personal_loan', 'bal_mortgage_loan', 'bal_current_account', 'bal_pension_saving', 'bal_savings_account', 'bal_savings_account_starter', 'bal_current_account_starter', 'visits_distinct_so', 'visits_distinct_so_areas', 'customer_since_all', 'customer_since_bank', 'customer_gender', 'customer_birth_date', 'customer_postal_code', 'customer_occupation_code', 'customer_self_employed', 'customer_education', 'customer_children', 'customer_relationship', 'target']\n",
    "\n",
    "\n",
    "https://www.statology.org/pandas-rename-columns/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "142b7f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv data files are in a folder called data\n",
    "file1 = \"../data/train_month_1.csv\"\n",
    "file2 = \"../data/train_month_2.csv\"\n",
    "file3 = \"../data/train_month_3_with_target.csv\"\n",
    "files = [file3, file2, file1]\n",
    "# https://stackoverflow.com/questions/68607106/creating-multiple-dataframes-using-for-loop-with-pandas\n",
    "# my_dfs = {}\n",
    "# for x in ['A', 'B', 'C']:\n",
    "#     my_dfs[x] = pd.read_csv(r\"C:\\HSTS\\OB\\ODO\\%s\\test.csv\" % x, delimiter=';')\n",
    "# Then access the dataframes per key:\n",
    "# my_dfs['A']\n",
    "\n",
    "listnames = ['data3', 'data2', 'data1']\n",
    "my_dfs = {}\n",
    "for i in range(3):\n",
    "    my_dfs[listnames[i]] = pd.read_csv(files[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bd9533c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data3\n",
      "data2\n",
      "data1\n"
     ]
    }
   ],
   "source": [
    "# https://www.tutorialspoint.com/How-to-iterate-through-a-dictionary-in-Python\n",
    "cols = [\"customer_since_all\", \"customer_since_bank\", \"customer_birth_date\"]\n",
    "# for column in stu_df[['Name', 'Section']]:\n",
    "# df[col] = pd.to_datetime(df[col])\n",
    "\n",
    "# This converts the 3 time cols in the 3 dfs to datetime format then subtracts 'current date' to get time since\n",
    "for k, v in my_dfs.items():\n",
    "    print(k)\n",
    "    for col in cols:\n",
    "        v[col] = (pd.to_datetime('2018-03-01') - pd.to_datetime(v[col])).dt.days\n",
    "        #v[col] = v[col].astype(int)\n",
    "        \n",
    "# if you run this more than once it gets confused, will have to start over by running the cell above too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ae778bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = my_dfs['data3']\n",
    "data2 = my_dfs['data2']\n",
    "data1 = my_dfs['data1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07ed4fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns with lag suffix\n",
    "data3.columns = ['client_id', 'homebanking_active_l0', 'has_homebanking_l0', 'has_insurance_21_l0', 'has_insurance_23_l0', 'has_life_insurance_fixed_cap_l0', 'has_life_insurance_decreasing_cap_l0', 'has_fire_car_other_insurance_l0', 'has_personal_loan_l0', 'has_mortgage_loan_l0', 'has_current_account_l0', 'has_pension_saving_l0', 'has_savings_account_l0', 'has_savings_account_starter_l0', 'has_current_account_starter_l0', 'bal_insurance_21_l0', 'bal_insurance_23_l0', 'cap_life_insurance_fixed_cap_l0', 'cap_life_insurance_decreasing_cap_l0', 'prem_fire_car_other_insurance_l0', 'bal_personal_loan_l0', 'bal_mortgage_loan_l0', 'bal_current_account_l0', 'bal_pension_saving_l0', 'bal_savings_account_l0', 'bal_savings_account_starter_l0', 'bal_current_account_starter_l0', 'visits_distinct_so_l0', 'visits_distinct_so_areas_l0', 'customer_since_all_l0', 'customer_since_bank_l0', 'customer_gender_l0', 'customer_birth_date_l0', 'customer_postal_code_l0', 'customer_occupation_code_l0', 'customer_self_employed_l0', 'customer_education_l0', 'customer_children_l0', 'customer_relationship_l0', 'target']\n",
    "data2.columns = ['client_id', 'homebanking_active_l1', 'has_homebanking_l1', 'has_insurance_21_l1', 'has_insurance_23_l1', 'has_life_insurance_fixed_cap_l1', 'has_life_insurance_decreasing_cap_l1', 'has_fire_car_other_insurance_l1', 'has_personal_loan_l1', 'has_mortgage_loan_l1', 'has_current_account_l1', 'has_pension_saving_l1', 'has_savings_account_l1', 'has_savings_account_starter_l1', 'has_current_account_starter_l1', 'bal_insurance_21_l1', 'bal_insurance_23_l1', 'cap_life_insurance_fixed_cap_l1', 'cap_life_insurance_decreasing_cap_l1', 'prem_fire_car_other_insurance_l1', 'bal_personal_loan_l1', 'bal_mortgage_loan_l1', 'bal_current_account_l1', 'bal_pension_saving_l1', 'bal_savings_account_l1', 'bal_savings_account_starter_l1', 'bal_current_account_starter_l1', 'visits_distinct_so_l1', 'visits_distinct_so_areas_l1', 'customer_since_all_l1', 'customer_since_bank_l1', 'customer_gender_l1', 'customer_birth_date_l1', 'customer_postal_code_l1', 'customer_occupation_code_l1', 'customer_self_employed_l1', 'customer_education_l1', 'customer_children_l1', 'customer_relationship_l1']\n",
    "data1.columns = ['client_id', 'homebanking_active_l2', 'has_homebanking_l2', 'has_insurance_21_l2', 'has_insurance_23_l2', 'has_life_insurance_fixed_cap_l2', 'has_life_insurance_decreasing_cap_l2', 'has_fire_car_other_insurance_l2', 'has_personal_loan_l2', 'has_mortgage_loan_l2', 'has_current_account_l2', 'has_pension_saving_l2', 'has_savings_account_l2', 'has_savings_account_starter_l2', 'has_current_account_starter_l2', 'bal_insurance_21_l2', 'bal_insurance_23_l2', 'cap_life_insurance_fixed_cap_l2', 'cap_life_insurance_decreasing_cap_l2', 'prem_fire_car_other_insurance_l2', 'bal_personal_loan_l2', 'bal_mortgage_loan_l2', 'bal_current_account_l2', 'bal_pension_saving_l2', 'bal_savings_account_l2', 'bal_savings_account_starter_l2', 'bal_current_account_starter_l2', 'visits_distinct_so_l2', 'visits_distinct_so_areas_l2', 'customer_since_all_l2', 'customer_since_bank_l2', 'customer_gender_l2', 'customer_birth_date_l2', 'customer_postal_code_l2', 'customer_occupation_code_l2', 'customer_self_employed_l2', 'customer_education_l2', 'customer_children_l2', 'customer_relationship_l2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "119a52b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the 3 data frames into one.\n",
    "data4 = data3.merge(data2, on='client_id', how='inner')\n",
    "data_Nans = data4.merge(data1, on='client_id', how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79fce486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values\n",
    "#imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "#imputer.fit(data)\n",
    "#data = pd.DataFrame(data=imputer.transform(data_Nans), columns=data_Nans.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fb23e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute without target for 115 columns to use with test data\n",
    "data_Nans = data_Nans.drop(columns='target', axis=1)\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "imputer.fit(data_Nans)\n",
    "data = pd.DataFrame(data=imputer.transform(data_Nans), columns=data_Nans.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8cbf69d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['no', 'mature', 'young', 'preschool', 'adolescent', 'grownup',\n",
       "       'onebaby', 'yes'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.customer_children_l0.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ccb223b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['couple', 'single'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.customer_relationship_l0.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10ab9357",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.edjefe.replace(to_replace=['no', 'yes'], value=[0, 1])\n",
    "data.replace(to_replace=['no', 'mature', 'young', 'preschool', 'adolescent', 'grownup', 'onebaby', 'yes'],\n",
    "             value=[0, 1, 1, 1, 1, 1, 1, 1], inplace=True)\n",
    "data.replace(to_replace=['couple', 'single'], value=[1, 0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3579ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63697, 115)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20198b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data3['target'].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0df8d78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.statology.org/drop-column-pandas/\n",
    "X = data.drop(columns='client_id', axis=1)\n",
    "# scaler = StandardScaler()\n",
    "# fit = scaler.fit(X)\n",
    "# Z = fit.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f291def6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivity(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sens = cm[1][1]/sum(cm[1])\n",
    "    return(sens)\n",
    "def pospredvalue(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    if (cm[0][1]+cm[1][1]) == 0:\n",
    "        return(0.0)\n",
    "    else:\n",
    "        ppv = cm[1][1]/(cm[0][1]+cm[1][1])\n",
    "        return(ppv)\n",
    "def totalfalserate(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tfr = (cm[0][1]+cm[1][0])/sum(sum(cm))\n",
    "    return(tfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5fe84b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for training/validation, assuming balanced classes\n",
    "# by default 75/25 split.  33 is a rndm seed - for reproducibility\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.25, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b83c18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a1fe722",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.describe()\n",
    "# this ignores columns that aren't purely numeric, including dates, but does include postal code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2cf529ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=2, random_state=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try a RF fit\n",
    "rf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "#rf.score(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df1b5ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9697331240188383"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "172aa78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15443     0]\n",
      " [  482     0]]\n"
     ]
    }
   ],
   "source": [
    "y_predrf = rf.predict(X_valid)\n",
    "print(confusion_matrix(y_valid, y_predrf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a742314d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensitivity(y_valid, y_predrf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20deb31c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pospredvalue(y_valid, y_predrf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33f8d15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn.metrics.roc_auc_score(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)\n",
    "#y_scorerf = rf.predic_proba(X_valid)\n",
    "#roc_auc_score(y_valid, y_scorerf)\n",
    "# AttributeError: 'RandomForestClassifier' object has no attribute 'predic_proba'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cd76bb02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\peter\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "c:\\users\\peter\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\xgboost\\data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.67329\tvalidation_0-map:0.06649\n",
      "[1]\tvalidation_0-auc:0.69718\tvalidation_0-map:0.07453\n",
      "[2]\tvalidation_0-auc:0.70382\tvalidation_0-map:0.07550\n",
      "[3]\tvalidation_0-auc:0.71688\tvalidation_0-map:0.07638\n",
      "[4]\tvalidation_0-auc:0.71843\tvalidation_0-map:0.07555\n",
      "[5]\tvalidation_0-auc:0.72110\tvalidation_0-map:0.07674\n",
      "[6]\tvalidation_0-auc:0.72077\tvalidation_0-map:0.07820\n",
      "[7]\tvalidation_0-auc:0.72576\tvalidation_0-map:0.08190\n",
      "[8]\tvalidation_0-auc:0.72599\tvalidation_0-map:0.08082\n",
      "[9]\tvalidation_0-auc:0.72352\tvalidation_0-map:0.08199\n",
      "[10]\tvalidation_0-auc:0.72131\tvalidation_0-map:0.08155\n",
      "[11]\tvalidation_0-auc:0.72590\tvalidation_0-map:0.08320\n",
      "[12]\tvalidation_0-auc:0.72380\tvalidation_0-map:0.08175\n",
      "[13]\tvalidation_0-auc:0.72457\tvalidation_0-map:0.08225\n",
      "[14]\tvalidation_0-auc:0.72492\tvalidation_0-map:0.08384\n",
      "[15]\tvalidation_0-auc:0.72451\tvalidation_0-map:0.08273\n",
      "[16]\tvalidation_0-auc:0.72640\tvalidation_0-map:0.08295\n",
      "[17]\tvalidation_0-auc:0.72653\tvalidation_0-map:0.08308\n",
      "[18]\tvalidation_0-auc:0.72549\tvalidation_0-map:0.08325\n",
      "[19]\tvalidation_0-auc:0.72389\tvalidation_0-map:0.08317\n",
      "[20]\tvalidation_0-auc:0.72182\tvalidation_0-map:0.08076\n",
      "[21]\tvalidation_0-auc:0.72332\tvalidation_0-map:0.08141\n",
      "[22]\tvalidation_0-auc:0.72235\tvalidation_0-map:0.08172\n",
      "[23]\tvalidation_0-auc:0.72160\tvalidation_0-map:0.08137\n",
      "[24]\tvalidation_0-auc:0.71968\tvalidation_0-map:0.08105\n",
      "[25]\tvalidation_0-auc:0.71902\tvalidation_0-map:0.08099\n",
      "[26]\tvalidation_0-auc:0.71835\tvalidation_0-map:0.07999\n",
      "[27]\tvalidation_0-auc:0.71517\tvalidation_0-map:0.07966\n",
      "[28]\tvalidation_0-auc:0.71372\tvalidation_0-map:0.07979\n",
      "[29]\tvalidation_0-auc:0.71191\tvalidation_0-map:0.07877\n",
      "[30]\tvalidation_0-auc:0.71065\tvalidation_0-map:0.07829\n",
      "[31]\tvalidation_0-auc:0.70970\tvalidation_0-map:0.07805\n",
      "[32]\tvalidation_0-auc:0.71065\tvalidation_0-map:0.07770\n",
      "[33]\tvalidation_0-auc:0.71026\tvalidation_0-map:0.07722\n",
      "[34]\tvalidation_0-auc:0.70996\tvalidation_0-map:0.07687\n",
      "[35]\tvalidation_0-auc:0.70992\tvalidation_0-map:0.07613\n",
      "[36]\tvalidation_0-auc:0.71048\tvalidation_0-map:0.07569\n",
      "[37]\tvalidation_0-auc:0.71037\tvalidation_0-map:0.07679\n",
      "[38]\tvalidation_0-auc:0.70890\tvalidation_0-map:0.07636\n",
      "[39]\tvalidation_0-auc:0.70935\tvalidation_0-map:0.07637\n",
      "[40]\tvalidation_0-auc:0.70805\tvalidation_0-map:0.07626\n",
      "[41]\tvalidation_0-auc:0.70860\tvalidation_0-map:0.07665\n",
      "[42]\tvalidation_0-auc:0.70832\tvalidation_0-map:0.07612\n",
      "[43]\tvalidation_0-auc:0.70903\tvalidation_0-map:0.07598\n",
      "[44]\tvalidation_0-auc:0.70784\tvalidation_0-map:0.07549\n",
      "[45]\tvalidation_0-auc:0.70772\tvalidation_0-map:0.07525\n",
      "[46]\tvalidation_0-auc:0.70652\tvalidation_0-map:0.07449\n",
      "[47]\tvalidation_0-auc:0.70703\tvalidation_0-map:0.07498\n",
      "[48]\tvalidation_0-auc:0.70576\tvalidation_0-map:0.07489\n",
      "[49]\tvalidation_0-auc:0.70496\tvalidation_0-map:0.07488\n",
      "[50]\tvalidation_0-auc:0.70353\tvalidation_0-map:0.07363\n",
      "[51]\tvalidation_0-auc:0.70545\tvalidation_0-map:0.07350\n",
      "[52]\tvalidation_0-auc:0.70524\tvalidation_0-map:0.07296\n",
      "[53]\tvalidation_0-auc:0.70506\tvalidation_0-map:0.07248\n",
      "[54]\tvalidation_0-auc:0.70553\tvalidation_0-map:0.07269\n",
      "[55]\tvalidation_0-auc:0.70543\tvalidation_0-map:0.07222\n",
      "[56]\tvalidation_0-auc:0.70563\tvalidation_0-map:0.07208\n",
      "[57]\tvalidation_0-auc:0.70534\tvalidation_0-map:0.07230\n",
      "[58]\tvalidation_0-auc:0.70443\tvalidation_0-map:0.07226\n",
      "[59]\tvalidation_0-auc:0.70433\tvalidation_0-map:0.07268\n",
      "[60]\tvalidation_0-auc:0.70301\tvalidation_0-map:0.07186\n",
      "[61]\tvalidation_0-auc:0.70268\tvalidation_0-map:0.07175\n",
      "[62]\tvalidation_0-auc:0.70295\tvalidation_0-map:0.07136\n",
      "[63]\tvalidation_0-auc:0.70262\tvalidation_0-map:0.07037\n",
      "[64]\tvalidation_0-auc:0.70263\tvalidation_0-map:0.07029\n",
      "[65]\tvalidation_0-auc:0.70185\tvalidation_0-map:0.06971\n",
      "[66]\tvalidation_0-auc:0.70132\tvalidation_0-map:0.06939\n",
      "[67]\tvalidation_0-auc:0.69969\tvalidation_0-map:0.06914\n",
      "[68]\tvalidation_0-auc:0.69930\tvalidation_0-map:0.06886\n",
      "[69]\tvalidation_0-auc:0.69912\tvalidation_0-map:0.06886\n",
      "[70]\tvalidation_0-auc:0.69871\tvalidation_0-map:0.06879\n",
      "[71]\tvalidation_0-auc:0.69810\tvalidation_0-map:0.06849\n",
      "[72]\tvalidation_0-auc:0.69793\tvalidation_0-map:0.06829\n",
      "[73]\tvalidation_0-auc:0.69754\tvalidation_0-map:0.06830\n",
      "[74]\tvalidation_0-auc:0.69733\tvalidation_0-map:0.06817\n",
      "[75]\tvalidation_0-auc:0.69702\tvalidation_0-map:0.06808\n",
      "[76]\tvalidation_0-auc:0.69552\tvalidation_0-map:0.06756\n",
      "[77]\tvalidation_0-auc:0.69522\tvalidation_0-map:0.06753\n",
      "[78]\tvalidation_0-auc:0.69572\tvalidation_0-map:0.06752\n",
      "[79]\tvalidation_0-auc:0.69555\tvalidation_0-map:0.06696\n",
      "[80]\tvalidation_0-auc:0.69515\tvalidation_0-map:0.06703\n",
      "[81]\tvalidation_0-auc:0.69551\tvalidation_0-map:0.06707\n",
      "[82]\tvalidation_0-auc:0.69340\tvalidation_0-map:0.06680\n",
      "[83]\tvalidation_0-auc:0.69334\tvalidation_0-map:0.06696\n",
      "[84]\tvalidation_0-auc:0.69340\tvalidation_0-map:0.06694\n",
      "[85]\tvalidation_0-auc:0.69373\tvalidation_0-map:0.06717\n",
      "[86]\tvalidation_0-auc:0.69261\tvalidation_0-map:0.06694\n",
      "[87]\tvalidation_0-auc:0.69242\tvalidation_0-map:0.06693\n",
      "[88]\tvalidation_0-auc:0.69250\tvalidation_0-map:0.06694\n",
      "[89]\tvalidation_0-auc:0.69197\tvalidation_0-map:0.06752\n",
      "[90]\tvalidation_0-auc:0.69025\tvalidation_0-map:0.06626\n",
      "[91]\tvalidation_0-auc:0.68991\tvalidation_0-map:0.06604\n",
      "[92]\tvalidation_0-auc:0.68971\tvalidation_0-map:0.06624\n",
      "[93]\tvalidation_0-auc:0.69006\tvalidation_0-map:0.06637\n",
      "[94]\tvalidation_0-auc:0.68974\tvalidation_0-map:0.06661\n",
      "[95]\tvalidation_0-auc:0.68983\tvalidation_0-map:0.06759\n",
      "[96]\tvalidation_0-auc:0.68980\tvalidation_0-map:0.06747\n",
      "[97]\tvalidation_0-auc:0.68943\tvalidation_0-map:0.06729\n",
      "[98]\tvalidation_0-auc:0.68987\tvalidation_0-map:0.06803\n",
      "[99]\tvalidation_0-auc:0.68769\tvalidation_0-map:0.06724\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              eval_metric=['auc', 'map'], gamma=0, gpu_id=-1,\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=8, num_parallel_tree=1, predictor='auto',\n",
       "              random_state=33, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.kaggle.com/code/stuarthallows/using-xgboost-with-scikit-learn/notebook\n",
    "# Try xgboost classifier\n",
    "xgb = XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric = ['auc', 'map'],\n",
    "    random_state=33\n",
    ")\n",
    "xgb.fit(X_train, y_train, eval_set=[(X_valid, y_valid)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a4916549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9696075353218211"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.score(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "055a6907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15439     4]\n",
      " [  480     2]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\peter\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\xgboost\\data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    }
   ],
   "source": [
    "y_predxgb = xgb.predict(X_valid)\n",
    "print(confusion_matrix(y_valid, y_predxgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0378a621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15439, 4, 480, 2)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_valid, y_predxgb).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0f8e7279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004149377593360996"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensitivity(y_valid, y_predxgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "12129c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.030392464678178965"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalfalserate(y_valid, y_predxgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "baf39705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# really slow: SVC(kernel=\"rbf\", C=0.025, probability=True),\n",
    "classifiers = [\n",
    "    RandomForestClassifier(max_depth=5, random_state=0)\n",
    "    KNeighborsClassifier(3),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    MLPClassifier((20,20), random_state=33, max_iter=500)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a8ef3bfb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\peter\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\base.py:441: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(n_neighbors=3)\n",
      "sensitivity: 0.0062\n",
      "total false rate: 0.0341\n",
      "-------------------------\n",
      "DecisionTreeClassifier()\n",
      "sensitivity: 0.0954\n",
      "total false rate: 0.0598\n",
      "-------------------------\n",
      "RandomForestClassifier()\n",
      "sensitivity: 0.0000\n",
      "total false rate: 0.0303\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\peter\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\base.py:441: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier()\n",
      "sensitivity: 0.0000\n",
      "total false rate: 0.0303\n",
      "-------------------------\n",
      "GradientBoostingClassifier()\n",
      "sensitivity: 0.0021\n",
      "total false rate: 0.0307\n",
      "-------------------------\n",
      "MLPClassifier(hidden_layer_sizes=(20, 20), max_iter=500, random_state=33)\n",
      "sensitivity: 0.0000\n",
      "total false rate: 0.0304\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "for classifier in classifiers:\n",
    "    classifier.fit(X_train, y_train)   \n",
    "    y_pred = classifier.predict(X_valid)\n",
    "    print(classifier)\n",
    "    print(\"sensitivity: %.4f\" % sensitivity(y_valid, y_pred))\n",
    "    print(\"total false rate: %.4f\" % totalfalserate(y_valid, y_pred))\n",
    "    print(\"-------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eb45a14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\peter\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\base.py:441: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(n_neighbors=1)\n",
      "sensitivity: 0.0519\n",
      "total false rate: 0.0550\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\peter\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\base.py:441: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(n_neighbors=3)\n",
      "sensitivity: 0.0062\n",
      "total false rate: 0.0341\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\peter\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\base.py:441: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier()\n",
      "sensitivity: 0.0021\n",
      "total false rate: 0.0309\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\peter\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\base.py:441: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(n_neighbors=7)\n",
      "sensitivity: 0.0021\n",
      "total false rate: 0.0306\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\peter\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\base.py:441: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(n_neighbors=9)\n",
      "sensitivity: 0.0000\n",
      "total false rate: 0.0303\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10, 2):\n",
    "    kn = KNeighborsClassifier(i)\n",
    "    kn.fit(X_train, y_train)\n",
    "    y_pred = kn.predict(X_valid)\n",
    "    print(kn)\n",
    "    print(\"sensitivity: %.4f\" % sensitivity(y_valid, y_pred))\n",
    "    print(\"total false rate: %.4f\" % totalfalserate(y_valid, y_pred))\n",
    "    print(\"-------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8f5252",
   "metadata": {},
   "source": [
    "## Now predict on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b4282844",
   "metadata": {},
   "outputs": [],
   "source": [
    "file1_test = \"../data/test_month_1.csv\"\n",
    "file2_test = \"../data/test_month_2.csv\"\n",
    "file3_test = \"../data/test_month_3.csv\"\n",
    "files_test = [file3_test, file2_test, file1_test]\n",
    "\n",
    "listnames_test = ['data3_test', 'data2_test', 'data1_test']\n",
    "my_dfs_test = {}\n",
    "for i in range(3):\n",
    "    my_dfs_test[listnames_test[i]] = pd.read_csv(files_test[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a02a6c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data3_test\n",
      "27300\n",
      "data2_test\n",
      "27300\n",
      "data1_test\n",
      "27300\n"
     ]
    }
   ],
   "source": [
    "# This converts the 3 time cols in the 3 dfs to datetime format then subtracts 'current date' to get time since\n",
    "cols_test = [\"customer_since_all\", \"customer_since_bank\", \"customer_birth_date\"]\n",
    "for k, v in my_dfs_test.items():\n",
    "    print(k)\n",
    "    print(len(v))\n",
    "    for col in cols_test:\n",
    "        v[col] = (pd.to_datetime('2018-03-01') - pd.to_datetime(v[col])).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ca004e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data3_test = my_dfs_test['data3_test']\n",
    "data2_test = my_dfs_test['data2_test']\n",
    "data1_test = my_dfs_test['data1_test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6837847c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns with lag suffix\n",
    "data3_test.columns = ['client_id', 'homebanking_active_l0', 'has_homebanking_l0', 'has_insurance_21_l0', 'has_insurance_23_l0', 'has_life_insurance_fixed_cap_l0', 'has_life_insurance_decreasing_cap_l0', 'has_fire_car_other_insurance_l0', 'has_personal_loan_l0', 'has_mortgage_loan_l0', 'has_current_account_l0', 'has_pension_saving_l0', 'has_savings_account_l0', 'has_savings_account_starter_l0', 'has_current_account_starter_l0', 'bal_insurance_21_l0', 'bal_insurance_23_l0', 'cap_life_insurance_fixed_cap_l0', 'cap_life_insurance_decreasing_cap_l0', 'prem_fire_car_other_insurance_l0', 'bal_personal_loan_l0', 'bal_mortgage_loan_l0', 'bal_current_account_l0', 'bal_pension_saving_l0', 'bal_savings_account_l0', 'bal_savings_account_starter_l0', 'bal_current_account_starter_l0', 'visits_distinct_so_l0', 'visits_distinct_so_areas_l0', 'customer_since_all_l0', 'customer_since_bank_l0', 'customer_gender_l0', 'customer_birth_date_l0', 'customer_postal_code_l0', 'customer_occupation_code_l0', 'customer_self_employed_l0', 'customer_education_l0', 'customer_children_l0', 'customer_relationship_l0']\n",
    "data2_test.columns = ['client_id', 'homebanking_active_l1', 'has_homebanking_l1', 'has_insurance_21_l1', 'has_insurance_23_l1', 'has_life_insurance_fixed_cap_l1', 'has_life_insurance_decreasing_cap_l1', 'has_fire_car_other_insurance_l1', 'has_personal_loan_l1', 'has_mortgage_loan_l1', 'has_current_account_l1', 'has_pension_saving_l1', 'has_savings_account_l1', 'has_savings_account_starter_l1', 'has_current_account_starter_l1', 'bal_insurance_21_l1', 'bal_insurance_23_l1', 'cap_life_insurance_fixed_cap_l1', 'cap_life_insurance_decreasing_cap_l1', 'prem_fire_car_other_insurance_l1', 'bal_personal_loan_l1', 'bal_mortgage_loan_l1', 'bal_current_account_l1', 'bal_pension_saving_l1', 'bal_savings_account_l1', 'bal_savings_account_starter_l1', 'bal_current_account_starter_l1', 'visits_distinct_so_l1', 'visits_distinct_so_areas_l1', 'customer_since_all_l1', 'customer_since_bank_l1', 'customer_gender_l1', 'customer_birth_date_l1', 'customer_postal_code_l1', 'customer_occupation_code_l1', 'customer_self_employed_l1', 'customer_education_l1', 'customer_children_l1', 'customer_relationship_l1']\n",
    "data1_test.columns = ['client_id', 'homebanking_active_l2', 'has_homebanking_l2', 'has_insurance_21_l2', 'has_insurance_23_l2', 'has_life_insurance_fixed_cap_l2', 'has_life_insurance_decreasing_cap_l2', 'has_fire_car_other_insurance_l2', 'has_personal_loan_l2', 'has_mortgage_loan_l2', 'has_current_account_l2', 'has_pension_saving_l2', 'has_savings_account_l2', 'has_savings_account_starter_l2', 'has_current_account_starter_l2', 'bal_insurance_21_l2', 'bal_insurance_23_l2', 'cap_life_insurance_fixed_cap_l2', 'cap_life_insurance_decreasing_cap_l2', 'prem_fire_car_other_insurance_l2', 'bal_personal_loan_l2', 'bal_mortgage_loan_l2', 'bal_current_account_l2', 'bal_pension_saving_l2', 'bal_savings_account_l2', 'bal_savings_account_starter_l2', 'bal_current_account_starter_l2', 'visits_distinct_so_l2', 'visits_distinct_so_areas_l2', 'customer_since_all_l2', 'customer_since_bank_l2', 'customer_gender_l2', 'customer_birth_date_l2', 'customer_postal_code_l2', 'customer_occupation_code_l2', 'customer_self_employed_l2', 'customer_education_l2', 'customer_children_l2', 'customer_relationship_l2']\n",
    "\n",
    "# Join the 3 data frames into one.\n",
    "data4_test = data3_test.merge(data2_test, on='client_id', how='inner')\n",
    "data_Nans_test = data4_test.merge(data1_test, on='client_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d9ff0ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values\n",
    "data_test = pd.DataFrame(data=imputer.transform(data_Nans_test), columns=data_Nans_test.columns)\n",
    "data_test.replace(to_replace=['no', 'mature', 'young', 'preschool', 'adolescent', 'grownup', 'onebaby', 'yes'],\n",
    "             value=[0, 1, 1, 1, 1, 1, 1, 1], inplace=True)\n",
    "data_test.replace(to_replace=['couple', 'single'], value=[1, 0], inplace=True)\n",
    "clientID = pd.DataFrame(data=data_test['client_id'])\n",
    "X_test = data_test.drop(columns='client_id', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512a1e7e",
   "metadata": {},
   "source": [
    "## Predict on test data and save as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4f6f7a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = pd.DataFrame(xgb.predict_proba(X_test))\n",
    "# Decision Tree did worse on the test data\n",
    "#y_pred_test = pd.DataFrame(dt.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3addd1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0         1\n",
      "0      0.984721  0.015279\n",
      "1      0.970955  0.029045\n",
      "2      0.918003  0.081997\n",
      "3      0.994368  0.005632\n",
      "4      0.978663  0.021337\n",
      "...         ...       ...\n",
      "27295  0.979317  0.020683\n",
      "27296  0.927633  0.072367\n",
      "27297  0.984245  0.015755\n",
      "27298  0.974884  0.025116\n",
      "27299  0.982389  0.017611\n",
      "\n",
      "[27300 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0a9c74f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clientID['pred']=y_pred_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ceef2fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clientID.to_csv(\"y_pred_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be7a17d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
