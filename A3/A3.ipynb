{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49b36a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "# Helper thread to avoid the Spark StreamingContext from blocking Jupyter\n",
    "        \n",
    "class StreamingThread(threading.Thread):\n",
    "    def __init__(self, ssc):\n",
    "        super().__init__()\n",
    "        self.ssc = ssc\n",
    "    def run(self):\n",
    "        self.ssc.start()\n",
    "        self.ssc.awaitTermination()\n",
    "    def stop(self):\n",
    "        print('----- Stopping... this may take a few seconds -----')\n",
    "        self.ssc.stop(stopSparkContext=False, stopGraceFully=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42af0834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-D2OUEDP:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e39a78ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-D2OUEDP:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1bfdb005670>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "507dfb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import download\n",
    "from nltk import word_tokenize\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.linalg import Vectors\n",
    "import pyarrow as pa # for creating spark dataframe\n",
    "from nltk import sent_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim import models\n",
    "import gensim.downloader as api\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.corpora import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "912f50a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\peter\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7258efd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'out', 'we', 'was', 'how', 'myself', 'for', 'they', 'about', \"hasn't\", 'then', 'both', 'so', 're', 'don', 'm', 'as', 'any', 'mightn', 'after', 'you', 'wouldn', 'why', 'been', 'where', 'by', \"isn't\", 'yourself', 'wasn', 'a', \"haven't\", 'did', \"hadn't\", 'their', 'hasn', 'doing', 'be', 'further', 'ours', 'now', 'am', 'her', \"you'll\", 'yourselves', 'that', 'my', 'what', 'to', 'd', 'not', \"won't\", \"couldn't\", 'own', 'there', 'this', 'each', 'all', 'haven', 'more', 'me', 've', 'weren', 'which', 'himself', 'nor', 'other', \"shouldn't\", 'who', \"should've\", 'same', 'at', 'such', 't', 'up', 'than', 'can', \"you've\", 'too', 'these', 'while', \"wasn't\", 'ourselves', 'before', 'i', 'he', \"didn't\", 'our', 'its', 'but', 'with', \"wouldn't\", 'those', 'because', 'the', 'y', 'shouldn', 'it', 'mustn', 'hers', 'just', 'doesn', 'ain', 'between', 'over', 'had', 'aren', \"mightn't\", 'does', 'have', 'and', 'or', 'some', \"mustn't\", 'only', 'won', 'when', 'needn', 'below', 'in', 'if', 'theirs', \"needn't\", \"aren't\", 'isn', 'again', 'his', 'whom', 'll', 'hadn', 'above', 'should', 'itself', 'themselves', 'until', 'are', 'she', 'no', 'from', 'into', 'will', 'your', 'few', 'herself', 'of', 'has', 'down', 'were', 'once', 'ma', 'having', 'them', 'under', 'him', 'shan', 'couldn', 'do', 'on', 'an', \"you'd\", 'yours', 'being', 'off', 'o', \"that'll\", 'very', \"weren't\", 'didn', 'through', \"you're\", 'most', 'against', \"it's\", \"doesn't\", 'here', 'is', 's', \"don't\", \"shan't\", 'during', \"she's\"}\n"
     ]
    }
   ],
   "source": [
    "# Print list of stopwords for informational purposes\n",
    "stops = set(stopwords.words('english'))\n",
    "print(stops)\n",
    "# We might consider removing some of these or making our own list since our text is weird"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2b38e1",
   "metadata": {},
   "source": [
    "<a href=\"https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf\" target=\"_blank\">Pandas cheat sheet</a><BR>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d063d9",
   "metadata": {},
   "source": [
    "<A HREF=\"https://spark.apache.org/docs/latest/ml-guide.html\" target=\"_blank\">Pyspark ML guide</A><BR>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fecf73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"messages.csv\")\n",
    "# Replace message NaNs with zero length string ''\n",
    "df.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8fa85f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>channel</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>y0urm0mg4y_19391</td>\n",
       "      <td>#xqcow</td>\n",
       "      <td>PagMan ðŸª£</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>heroo117</td>\n",
       "      <td>#xqcow</td>\n",
       "      <td>THIS IS JUST LIKE OW2 BatChest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deeznipzzz</td>\n",
       "      <td>#summit1g</td>\n",
       "      <td>blue is crashing at some point can already tel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>masterchiefkief</td>\n",
       "      <td>#xqcow</td>\n",
       "      <td>sheep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bugballo</td>\n",
       "      <td>#xqcow</td>\n",
       "      <td>press e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           username    channel  \\\n",
       "0  y0urm0mg4y_19391     #xqcow   \n",
       "1          heroo117     #xqcow   \n",
       "2        deeznipzzz  #summit1g   \n",
       "3   masterchiefkief     #xqcow   \n",
       "4          bugballo     #xqcow   \n",
       "\n",
       "                                             message  \n",
       "0                                           PagMan ðŸª£  \n",
       "1                     THIS IS JUST LIKE OW2 BatChest  \n",
       "2  blue is crashing at some point can already tel...  \n",
       "3                                              sheep  \n",
       "4                                            press e  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb4cb314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>channel</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>y0urm0mg4y_19391</td>\n",
       "      <td>#xqcow</td>\n",
       "      <td>PagMan ðŸª£</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>heroo117</td>\n",
       "      <td>#xqcow</td>\n",
       "      <td>THIS IS JUST LIKE OW2 BatChest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deeznipzzz</td>\n",
       "      <td>#summit1g</td>\n",
       "      <td>blue is crashing at some point can already tel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>masterchiefkief</td>\n",
       "      <td>#xqcow</td>\n",
       "      <td>sheep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bugballo</td>\n",
       "      <td>#xqcow</td>\n",
       "      <td>press e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6003</th>\n",
       "      <td>upgraydded</td>\n",
       "      <td>#summit1g</td>\n",
       "      <td>Pornhub in VR Pog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6004</th>\n",
       "      <td>loukangbang</td>\n",
       "      <td>#summit1g</td>\n",
       "      <td>INSTALL ITTTT PauseChamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6005</th>\n",
       "      <td>drethaprince</td>\n",
       "      <td>#summit1g</td>\n",
       "      <td>Did something to Fortnite?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6006</th>\n",
       "      <td>okiasmegalos</td>\n",
       "      <td>#xqcow</td>\n",
       "      <td>The daleks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6007</th>\n",
       "      <td>potlug</td>\n",
       "      <td>#xqcow</td>\n",
       "      <td>FeelsOkayMan &lt;3 goodnight chat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6008 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              username    channel  \\\n",
       "0     y0urm0mg4y_19391     #xqcow   \n",
       "1             heroo117     #xqcow   \n",
       "2           deeznipzzz  #summit1g   \n",
       "3      masterchiefkief     #xqcow   \n",
       "4             bugballo     #xqcow   \n",
       "...                ...        ...   \n",
       "6003        upgraydded  #summit1g   \n",
       "6004       loukangbang  #summit1g   \n",
       "6005      drethaprince  #summit1g   \n",
       "6006      okiasmegalos     #xqcow   \n",
       "6007            potlug     #xqcow   \n",
       "\n",
       "                                                message  \n",
       "0                                              PagMan ðŸª£  \n",
       "1                        THIS IS JUST LIKE OW2 BatChest  \n",
       "2     blue is crashing at some point can already tel...  \n",
       "3                                                 sheep  \n",
       "4                                               press e  \n",
       "...                                                 ...  \n",
       "6003                                  Pornhub in VR Pog  \n",
       "6004                           INSTALL ITTTT PauseChamp  \n",
       "6005                         Did something to Fortnite?  \n",
       "6006                                         The daleks  \n",
       "6007                     FeelsOkayMan <3 goodnight chat  \n",
       "\n",
       "[6008 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fa63877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channel 0 is  #xqcow\n"
     ]
    }
   ],
   "source": [
    "# Only for 2 channel's of data\n",
    "# codes channel in 1st row as 0, other channel is 1\n",
    "df['target'] = pd.DataFrame(np.where(df.channel==df.channel[0], 0, 1))\n",
    "print('channel 0 is ',df.channel[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b61053",
   "metadata": {},
   "source": [
    "<a href=\"https://www.programiz.com/python-programming/list-comprehension\" target=\"_blank\">List comprehension</a><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6ecc4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize words\n",
    "df['tokens'] = [word_tokenize(string) for string in df['message']]\n",
    "df['tokens'] = [[word.lower() for word in token] for token in df['tokens'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70161c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stop words\n",
    "df['tokens'] = [[word for word in token if word not in stopwords.words('english') ] for token in df['tokens']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73426fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove blanks ''\n",
    "df['tokens'] = [[word for word in token if len(word) > 0] for token in df['tokens']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1a99e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of words in tokens\n",
    "df['count'] = [len(token) for token in df['tokens']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d53371",
   "metadata": {},
   "source": [
    "Since many of these aren't words, I think stemming and lemmatization are not useful here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8b4474b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>channel</th>\n",
       "      <th>message</th>\n",
       "      <th>target</th>\n",
       "      <th>tokens</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>y0urm0mg4y_19391</td>\n",
       "      <td>#xqcow</td>\n",
       "      <td>PagMan ðŸª£</td>\n",
       "      <td>0</td>\n",
       "      <td>[pagman, ðŸª£]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>heroo117</td>\n",
       "      <td>#xqcow</td>\n",
       "      <td>THIS IS JUST LIKE OW2 BatChest</td>\n",
       "      <td>0</td>\n",
       "      <td>[like, ow2, batchest]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deeznipzzz</td>\n",
       "      <td>#summit1g</td>\n",
       "      <td>blue is crashing at some point can already tel...</td>\n",
       "      <td>1</td>\n",
       "      <td>[blue, crashing, point, already, tell, wait, lol]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>masterchiefkief</td>\n",
       "      <td>#xqcow</td>\n",
       "      <td>sheep</td>\n",
       "      <td>0</td>\n",
       "      <td>[sheep]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bugballo</td>\n",
       "      <td>#xqcow</td>\n",
       "      <td>press e</td>\n",
       "      <td>0</td>\n",
       "      <td>[press, e]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6003</th>\n",
       "      <td>upgraydded</td>\n",
       "      <td>#summit1g</td>\n",
       "      <td>Pornhub in VR Pog</td>\n",
       "      <td>1</td>\n",
       "      <td>[pornhub, vr, pog]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6004</th>\n",
       "      <td>loukangbang</td>\n",
       "      <td>#summit1g</td>\n",
       "      <td>INSTALL ITTTT PauseChamp</td>\n",
       "      <td>1</td>\n",
       "      <td>[install, itttt, pausechamp]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6005</th>\n",
       "      <td>drethaprince</td>\n",
       "      <td>#summit1g</td>\n",
       "      <td>Did something to Fortnite?</td>\n",
       "      <td>1</td>\n",
       "      <td>[something, fortnite, ?]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6006</th>\n",
       "      <td>okiasmegalos</td>\n",
       "      <td>#xqcow</td>\n",
       "      <td>The daleks</td>\n",
       "      <td>0</td>\n",
       "      <td>[daleks]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6007</th>\n",
       "      <td>potlug</td>\n",
       "      <td>#xqcow</td>\n",
       "      <td>FeelsOkayMan &lt;3 goodnight chat</td>\n",
       "      <td>0</td>\n",
       "      <td>[feelsokayman, &lt;, 3, goodnight, chat]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6008 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              username    channel  \\\n",
       "0     y0urm0mg4y_19391     #xqcow   \n",
       "1             heroo117     #xqcow   \n",
       "2           deeznipzzz  #summit1g   \n",
       "3      masterchiefkief     #xqcow   \n",
       "4             bugballo     #xqcow   \n",
       "...                ...        ...   \n",
       "6003        upgraydded  #summit1g   \n",
       "6004       loukangbang  #summit1g   \n",
       "6005      drethaprince  #summit1g   \n",
       "6006      okiasmegalos     #xqcow   \n",
       "6007            potlug     #xqcow   \n",
       "\n",
       "                                                message  target  \\\n",
       "0                                              PagMan ðŸª£       0   \n",
       "1                        THIS IS JUST LIKE OW2 BatChest       0   \n",
       "2     blue is crashing at some point can already tel...       1   \n",
       "3                                                 sheep       0   \n",
       "4                                               press e       0   \n",
       "...                                                 ...     ...   \n",
       "6003                                  Pornhub in VR Pog       1   \n",
       "6004                           INSTALL ITTTT PauseChamp       1   \n",
       "6005                         Did something to Fortnite?       1   \n",
       "6006                                         The daleks       0   \n",
       "6007                     FeelsOkayMan <3 goodnight chat       0   \n",
       "\n",
       "                                                 tokens  count  \n",
       "0                                           [pagman, ðŸª£]      2  \n",
       "1                                 [like, ow2, batchest]      3  \n",
       "2     [blue, crashing, point, already, tell, wait, lol]      7  \n",
       "3                                               [sheep]      1  \n",
       "4                                            [press, e]      2  \n",
       "...                                                 ...    ...  \n",
       "6003                                 [pornhub, vr, pog]      3  \n",
       "6004                       [install, itttt, pausechamp]      3  \n",
       "6005                           [something, fortnite, ?]      3  \n",
       "6006                                           [daleks]      1  \n",
       "6007              [feelsokayman, <, 3, goodnight, chat]      5  \n",
       "\n",
       "[6008 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0bcc86fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ch0 = df.query('target == 0')\n",
    "ch1 = df.query('target == 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8263f6fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>channel</th>\n",
       "      <th>message</th>\n",
       "      <th>target</th>\n",
       "      <th>tokens</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deeznipzzz</td>\n",
       "      <td>#summit1g</td>\n",
       "      <td>blue is crashing at some point can already tel...</td>\n",
       "      <td>1</td>\n",
       "      <td>[blue, crashing, point, already, tell, wait, lol]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>jabrony67</td>\n",
       "      <td>#summit1g</td>\n",
       "      <td>HELL YEAH</td>\n",
       "      <td>1</td>\n",
       "      <td>[hell, yeah]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>mekerakesh</td>\n",
       "      <td>#summit1g</td>\n",
       "      <td>Tyres up to temp, should be a nice smooth race...</td>\n",
       "      <td>1</td>\n",
       "      <td>[tyres, temp, ,, nice, smooth, race]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>temporarilyoutoforder</td>\n",
       "      <td>#summit1g</td>\n",
       "      <td>holy shit i havnt seen him play this much but ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[holy, shit, havnt, seen, play, much, man, got...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>filcher___</td>\n",
       "      <td>#summit1g</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 username    channel  \\\n",
       "2              deeznipzzz  #summit1g   \n",
       "31              jabrony67  #summit1g   \n",
       "46             mekerakesh  #summit1g   \n",
       "59  temporarilyoutoforder  #summit1g   \n",
       "70             filcher___  #summit1g   \n",
       "\n",
       "                                              message  target  \\\n",
       "2   blue is crashing at some point can already tel...       1   \n",
       "31                                          HELL YEAH       1   \n",
       "46  Tyres up to temp, should be a nice smooth race...       1   \n",
       "59  holy shit i havnt seen him play this much but ...       1   \n",
       "70                                                  1       1   \n",
       "\n",
       "                                               tokens  count  \n",
       "2   [blue, crashing, point, already, tell, wait, lol]      7  \n",
       "31                                       [hell, yeah]      2  \n",
       "46               [tyres, temp, ,, nice, smooth, race]      6  \n",
       "59  [holy, shit, havnt, seen, play, much, man, got...      9  \n",
       "70                                                [1]      1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2557e92",
   "metadata": {},
   "source": [
    "OK, try to make a Bag-O-Words for both channels' tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aeed6cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "allwords0 = [[word for word in token[0].split() ] for token in ch0['tokens'] if len(token)>0]\n",
    "# flat_list = [item for sublist in list_of_lists for item in sublist]\n",
    "allwords0 = np.unique(np.array([item for sublist in allwords0 for item in sublist]))\n",
    "allwords1 = [[word for word in token[0].split() ] for token in ch1['tokens'] if len(token)>0]\n",
    "# flat_list = [item for sublist in list_of_lists for item in sublist]\n",
    "allwords1 = np.unique(np.array([item for sublist in allwords1 for item in sublist]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "acfda0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok let's make a master list of all words\n",
    "allwords = [[word for word in token[0].split() ] for token in df['tokens'] if len(token)>0 ]\n",
    "# flat_list = [item for sublist in list_of_lists for item in sublist]\n",
    "allwords = np.unique(np.array([item for sublist in allwords for item in sublist]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83acd869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['\\x01action', '!', '#', ..., 'ðŸ§¹', 'ðŸ©°', 'ðŸª£'], dtype='<U30')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1a1e49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6e5a003f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2,stop_words='english')\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['message'])\n",
    "dfTFIDF = tfidf_matrix.toarray()\n",
    "tfid_feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "for i in range(dfTFIDF.shape[0]):\n",
    "    dfTFIDF[i].flatten\n",
    "dfTFIDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe366fc",
   "metadata": {},
   "source": [
    "<A HREF=\"https://radimrehurek.com/gensim/models/tfidfmodel.html?highlight=tfidfmodel\">TF-IDF Model docs</A>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bc947a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57ba86bc",
   "metadata": {},
   "source": [
    "#### Ok, time to try a spark ML model. I'm working off the example <a href='https://spark.apache.org/docs/latest/ml-pipeline.html#code-examples'>here</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92844ecf",
   "metadata": {},
   "source": [
    "I'm disliking pandas' dataframe it doesn't understand what I want, using numpy\n",
    "<A HREF=\"http://www.cheat-sheets.org/saved-copy/numpy-cheat-sheet.20210604.pdf\">Numpy cheat sheet</A>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "7710b2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6008, 1132)\n",
      "(6008, 1)\n"
     ]
    }
   ],
   "source": [
    "# move pandas df to spark df and tell it what are the features and what is the label\n",
    "df4spark = np.array(dfTFIDF)\n",
    "print(df4spark.shape)\n",
    "target = np.array(df['target'])\n",
    "target = np.reshape(target, (len(dfTFIDF), 1))\n",
    "print(target.shape)\n",
    "df4spark = np.concatenate((df4spark,target),axis=1) \n",
    "df4spark = pd.DataFrame(df4spark)\n",
    "spark.conf.set('spark.sql.execution.arrow.pyspark.enabled', \"true\")\n",
    "training = spark.createDataFrame(df4spark, [\"features\", \"label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "de4c81ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[features: array<bigint>, label: int]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "50b05f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LogisticRegression instance. This instance is an Estimator.\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d1182ecb",
   "metadata": {},
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "requirement failed: Column features must be of type class org.apache.spark.ml.linalg.VectorUDT:struct<type:tinyint,size:int,indices:array<int>,values:array<double>> but was actually class org.apache.spark.sql.types.ArrayType:array<bigint>.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7640\\4237850938.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Learn a LogisticRegression model. This uses the parameters stored in lr.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\spark\\spark\\spark-3.2.1-bin-hadoop2.7\\python\\pyspark\\ml\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m    159\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m             raise TypeError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[1;32m~\\Documents\\spark\\spark\\spark-3.2.1-bin-hadoop2.7\\python\\pyspark\\ml\\wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 335\u001b[1;33m         \u001b[0mjava_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    336\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\spark\\spark\\spark-3.2.1-bin-hadoop2.7\\python\\pyspark\\ml\\wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \"\"\"\n\u001b[0;32m    331\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\spark\\spark\\spark-3.2.1-bin-hadoop2.7\\python\\lib\\py4j-0.10.9.3-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1321\u001b[1;33m         return_value = get_return_value(\n\u001b[0m\u001b[0;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0;32m   1323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\spark\\spark\\spark-3.2.1-bin-hadoop2.7\\python\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    115\u001b[0m                 \u001b[1;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[1;31m# JVM exception message.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIllegalArgumentException\u001b[0m: requirement failed: Column features must be of type class org.apache.spark.ml.linalg.VectorUDT:struct<type:tinyint,size:int,indices:array<int>,values:array<double>> but was actually class org.apache.spark.sql.types.ArrayType:array<bigint>."
     ]
    }
   ],
   "source": [
    "# Learn a LogisticRegression model. This uses the parameters stored in lr.\n",
    "model1 = lr.fit(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94f3459",
   "metadata": {},
   "source": [
    "# All Spark All the Time!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea081ab",
   "metadata": {},
   "source": [
    "<A HREF=\"https://spark.apache.org/docs/latest/ml-features.html#feature-extractors\">Spark examples with text</A><BR>\n",
    "<A HREF=\"https://datacamp-community-prod.s3.amazonaws.com/02213cb4-b391-4516-adcd-57243ced8eed\">Spark dataframe cheat sheet</A><BR>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "ca64db19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "7b30c7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[username: string, channel: string, message: string]\n"
     ]
    }
   ],
   "source": [
    "sdf = spark.read.csv('messages.csv', header=True)\n",
    "sdf.na.drop()\n",
    "print(sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "f186e1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------+--------------------+------+\n",
      "|        username|  channel|             message|target|\n",
      "+----------------+---------+--------------------+------+\n",
      "|y0urm0mg4y_19391|   #xqcow|           PagMan ðŸª£|     0|\n",
      "|        heroo117|   #xqcow|THIS IS JUST LIKE...|     0|\n",
      "|      deeznipzzz|#summit1g|blue is crashing ...|     1|\n",
      "| masterchiefkief|   #xqcow|               sheep|     0|\n",
      "|        bugballo|   #xqcow|             press e|     0|\n",
      "|          sevrys|   #xqcow|because its the s...|     0|\n",
      "|          xannyi|   #xqcow|         GIGACHAD ðŸª£|     0|\n",
      "|         xfiishy|   #xqcow|           PagMan ðŸª£|     0|\n",
      "|         thawght|   #xqcow|The bucket can ch...|     0|\n",
      "|            dqzz|   #xqcow|           PepeLaugh|     0|\n",
      "|         malrysn|   #xqcow|PeepoGlad remembe...|     0|\n",
      "|    gamestarioni|   #xqcow|           PagMan ðŸª£|     0|\n",
      "| johnnystick5738|   #xqcow|               RIGHT|     0|\n",
      "|         sharis3|   #xqcow|       OW 2 OMEGALUL|     0|\n",
      "| swedish_remixer|   #xqcow|just like overwatch!|     0|\n",
      "|         knexius|   #xqcow|   bucket is content|     0|\n",
      "|         jmproxy|   #xqcow|           PagMan ðŸª£|     0|\n",
      "|         cor3ym8|   #xqcow|THIS IS A BUCKET....|     0|\n",
      "|   swooshkaboosh|   #xqcow|     TrollDespair ðŸª£|     0|\n",
      "|        damaxcus|   #xqcow|            !lewd ó €€|     0|\n",
      "+----------------+---------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf1 = sdf.withColumn('target', F.when(sdf.channel == df.channel[0], 0).otherwise(1) )\n",
    "sdf1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "41973ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------+--------------------+------+--------------------+\n",
      "|        username|  channel|             message|target|            messages|\n",
      "+----------------+---------+--------------------+------+--------------------+\n",
      "|y0urm0mg4y_19391|   #xqcow|           PagMan ðŸª£|     0|           PagMan ðŸª£|\n",
      "|        heroo117|   #xqcow|THIS IS JUST LIKE...|     0|THIS IS JUST LIKE...|\n",
      "|      deeznipzzz|#summit1g|blue is crashing ...|     1|blue is crashing ...|\n",
      "| masterchiefkief|   #xqcow|               sheep|     0|               sheep|\n",
      "|        bugballo|   #xqcow|             press e|     0|             press e|\n",
      "|          sevrys|   #xqcow|because its the s...|     0|because its the s...|\n",
      "|          xannyi|   #xqcow|         GIGACHAD ðŸª£|     0|         GIGACHAD ðŸª£|\n",
      "|         xfiishy|   #xqcow|           PagMan ðŸª£|     0|           PagMan ðŸª£|\n",
      "|         thawght|   #xqcow|The bucket can ch...|     0|The bucket can ch...|\n",
      "|            dqzz|   #xqcow|           PepeLaugh|     0|           PepeLaugh|\n",
      "|         malrysn|   #xqcow|PeepoGlad remembe...|     0|PeepoGlad remembe...|\n",
      "|    gamestarioni|   #xqcow|           PagMan ðŸª£|     0|           PagMan ðŸª£|\n",
      "| johnnystick5738|   #xqcow|               RIGHT|     0|               RIGHT|\n",
      "|         sharis3|   #xqcow|       OW 2 OMEGALUL|     0|       OW 2 OMEGALUL|\n",
      "| swedish_remixer|   #xqcow|just like overwatch!|     0|just like overwatch!|\n",
      "|         knexius|   #xqcow|   bucket is content|     0|   bucket is content|\n",
      "|         jmproxy|   #xqcow|           PagMan ðŸª£|     0|           PagMan ðŸª£|\n",
      "|         cor3ym8|   #xqcow|THIS IS A BUCKET....|     0|THIS IS A BUCKET....|\n",
      "|   swooshkaboosh|   #xqcow|     TrollDespair ðŸª£|     0|     TrollDespair ðŸª£|\n",
      "|        damaxcus|   #xqcow|            !lewd ó €€|     0|            !lewd ó €€|\n",
      "+----------------+---------+--------------------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf1 = sdf1.withColumn('messages', ltrim(sdf.message) ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "7c8d9de3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute '_jdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7640\\3748175450.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputCol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"messages\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputCol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"words\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mwordsDat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msdf1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\spark\\spark\\spark-3.2.1-bin-hadoop2.7\\python\\pyspark\\ml\\base.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m    215\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Params must be a param map but got %s.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\spark\\spark\\spark-3.2.1-bin-hadoop2.7\\python\\pyspark\\ml\\wrapper.py\u001b[0m in \u001b[0;36m_transform\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    348\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 350\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute '_jdf'"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = Tokenizer(inputCol=\"message\", outputCol=\"words\")\n",
    "wordsDat = tokenizer.transform(sdf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "6fe3e8ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute '_jdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7640\\3318942110.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mhashingTF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mHashingTF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputCol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"words\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputCol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"rawFeatures\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumFeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfeaturizedData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhashingTF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwordsData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\spark\\spark\\spark-3.2.1-bin-hadoop2.7\\python\\pyspark\\ml\\base.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m    215\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Params must be a param map but got %s.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\spark\\spark\\spark-3.2.1-bin-hadoop2.7\\python\\pyspark\\ml\\wrapper.py\u001b[0m in \u001b[0;36m_transform\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    348\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 350\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute '_jdf'"
     ]
    }
   ],
   "source": [
    "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=20)\n",
    "featurizedData = hashingTF.transform(wordsData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44990954",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
